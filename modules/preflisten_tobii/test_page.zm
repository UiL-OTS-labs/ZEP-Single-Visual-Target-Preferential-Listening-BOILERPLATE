/******************************************************************************\
FILE:           test_page.zm
AUTHOR:         Theo Veenker (UiL-OTS) <T.J.G.Veenker@uu.nl>
ADAPTED BY:     -

DESCRIPTION:

Provides a page object to show to the participant during test phase trials.
It handles presenting the stimulus and recording the participant's response.


HISTORY:
2012-11-10 TV   Created. Same as EyeLink version without EyeLink specifics.

\******************************************************************************/


Page test_page
{
    TestItem    item;           // trial control parameters
    string[..]  sounds;         // array of sound file names


    init()
    {
        fill_pattern_color = TEST_PAGE_COLOR;
    }


    on_event:key_press()
    {
        if (eyetracker.handle_key(input_key, input_modifiers)) 
            ;
        else
            handle_special_key(this, input_key, input_modifiers);
    }


    VerticalLayout layout
    {
        init()
        {
            spacing = 50;
            height = 0;     // 0 means as large as possible
        }


        CanvasGadget canvas
        {
            init()
            {
                fill_pattern_color = TEST_PAGE_STIMULUS_COLOR;
                size = 800, 800;
                offset_x = width / 2;
                offset_y = height / 2;
            }


            on_event:pre_start()
            {
                stimulus.is_visible = true;
            }


            on_event:start()
            {
//                int dt = int(now() - start_time);
//                eyetracker.print_to_data_file("SYNCTIME " + string(dt));
//                eyetracker.print_to_data_file(string(dt) + "DISPLAY ON");

                // Start first auditory stimulus at visual stimulus onset + 
                // INTERSTIMULUS_INTERVAL.
                time audonsettime = auditory_stimulus.play(start_time + 
                    INTERSTIMULUS_INTERVAL);

                // Enable gaze monitoring at onset of first auditory stimulus.
                response.start(audonsettime);
            }


            ImageShape attention
            {
                void load(string fn, int w=0)
                {
                    image = fn;
                    if (w > 0) {
                        width = w;
                        height = -1;
                    }
                    else {
                        width = 0;
                        height = 0;
                    }
                    x = -actual_width / 2;
                    y = -actual_height / 2;
                }


                on_event:pre_update()
                {
                    real t = relative_frame * 
                        real(display_device.refresh_interval) * 1e-3;
                    rotation = 0.1 * M_PI * sin(2 * M_PI * 0.5 * t);
                }


                on_event:start()
                {
                    sound_playback2.play(
                        stimuli_dir() + "sounds/" + ATTENTION_SOUND1, 
                        stimuli_dir() + "sounds/" + ATTENTION_SOUND2, 
                        event_time + 250ms, 250ms);
                }


                on_event:finish()
                {
                    sound_playback2.abort();

                    // Let eye-tracker record eye-movement data. Will stop at 
                    // end of trial.
                    eyetracker.target_page = test_page;
                    eyetracker.target = test_page;
                    eyetracker.start_tracking();
                }
            }


            ImageShape stimulus
            {
                void load(string fn, int w=0)
                {
                    image = fn;
                    if (w > 0) {
                        width = w;
                        height = -1;
                    }
                    else {
                        width = 0;
                        height = 0;
                    }
                    x = -actual_width / 2;
                    y = -actual_height / 2;
                }
            }
        }


        time start_attention_getter(time t)
        {
            // Prepare stimulus presentation objects.
            canvas.attention.load(stimuli_dir() + "images/" + ATTENTION_IMAGE);
        
            // Start picture stimulus.
            canvas.attention.start(t, ATTENTION_GETTER_DURATION);

            // Return stimulus onset time.
            return canvas.attention.expected_finish_time;
        }


        time start_stimulus(time t)
        {
            // Prepare stimulus presentation objects.
//            canvas.stimulus.load(stimuli_dir() + "images/" + item.imgfn);
            canvas.stimulus.load(stimuli_dir() + "images/" + item.imgfn, 
                canvas.width);

            // Start picture stimulus.
            canvas.start(t);

            // Return stimulus onset time.
            return canvas.expected_start_time;
        }


        void reset()
        {
            full_abort();

            canvas.stimulus.is_visible = false;
        }
    }


    SoundChain auditory_stimulus
    {
        int     index;          // index of current sound


        // Sound source/producer object.
        SoundFile clip {}


        // Sound sink/consumer object.
        SoundPlayback playback {}


        on_event:start()
        {
//            eyetracker.print_to_data_file("SOUND ON " + sounds[index]);
        }


        on_event:finish()
        {
//            eyetracker.print_to_data_file("SOUND OFF " + sounds[index]);

            index++;
            if (index < sounds.size && sounds[index] != "")
            {
                clip.file = stimuli_dir() + "sounds/" + sounds[index];

                start(finish_time + INTERSTIMULUS_INTERVAL);

                if (index + 1 == sounds.size || sounds[index + 1] == "")
                    response.stop(expected_finish_time + INTERSTIMULUS_INTERVAL);
            }
        }


        time play(time t)
        {
            abort();

            index = 0;
            playback.device = sound_output_device;
            clip.file = stimuli_dir() + "sounds/" + sounds[index];

            start(t);

            return expected_start_time;
        }
    }


    Response response
    {
        bool    looking;        // true while looking
        time    lookstart;      // looking state start time
        time    nolookstart;    // not-looking state start time
        dur     curlt;          // duration of current looking state
        dur     curnlt;         // duration of current not-looking state

        // Response data.
        dur     cumlt;          // cumulative looking time (duration)
        dur     cumnlt;         // cumulative not-looking time (duration)
        bool    lookedaway;     // if set, infant looked away too long


        void clear()
        {
            looking = false;
            lookstart = time(0);
            nolookstart = time(0);
            curlt = 0ms;
            curnlt = 0ms;
            cumlt = 0ms;
            cumnlt = 0ms;
            lookedaway = false;
        }


        void check_gaze_position(real xeye, real yeye, time t)
        {
            // Passed eye positions are relative to the test window.

            // Make eye coordinates relative to canvas.
            xeye -= layout.canvas.x;
            yeye -= layout.canvas.y;

            if (xeye < 0 || xeye >= layout.canvas.width ||
                    yeye < 0 || yeye >= layout.canvas.height) 
                looking = false;
            else
                looking = true;

            // Evaluate looking during the response period.
            if (check_hit(t) == HIT_VALID)
            {
                if (looking)
                {
                    if (lookstart == time(0)) 
                    {
                        cumnlt += curnlt;
                        curnlt = 0ms;
                        lookstart = t;
                        nolookstart = time(0);
                    }
                    curlt = t - lookstart;
                }
                else
                {
                    if (nolookstart == time(0)) 
                    {
                        cumlt += curlt;
                        curlt = 0ms;
                        nolookstart = t;
                        lookstart = time(0);
                    }
                    curnlt = t - nolookstart;
                    
                    if (MAX_LOOKAWAY_DURATION > 0ms && 
                        curnlt >= MAX_LOOKAWAY_DURATION)
                    {
                        lookedaway = true;
                        stop();
                    }
                }
            }
        }


        on_event:finish()
        {
            cumlt += curlt;
            cumnlt += curnlt;
            eyetracker.stop_tracking();
            done(CONTINUE);
        }
    }


    // Aborts any ongoing activity on this page and signals the initiator
    // of the trial that we're done.
    void done(int msgid)
    {
        // Just in case; abort presentation if still active.
        layout.reset();
        auditory_stimulus.abort();

        signal_target(msgid);   // tell caller we're done
        target = null;

        control.clear_status();
    }


    // Shows this page (if not yet done) and determines when the trial 
    // should begin. Called from action() below.
    time prepare_trial_start(time tref)
    {
        // Activate the test window so it gets the keyboard focus.
        test_window1.activate();

        // Show this page if not yet shown.
        int alreadyshown = test_window1.show_page(this, 
            tref + PAGE_TRANSITION_DELAY, PAGE_TRANSITION_DURATION);

        // If not yet shown make tref the time it will become fully visible.
        if (!alreadyshown) tref = expected_transition_finish_time;

        // First trial should begin FIRST_TRIAL_DELAY from tref. Following
        // trials should begin INTERTRIAL_INTERVAL from tref.
        if (!alreadyshown)
            tref += FIRST_TRIAL_DELAY;
        else
            tref += INTERTRIAL_INTERVAL;

        return tref;
    }


    //==========================================================================


    // Performs preparatory work required before using this page.
    void setup()
    {
    }


    // Performs cleaning up if necessary.
    void cleanup()
    {
        layout.reset();
        auditory_stimulus.abort();
        sound_playback2.abort();
    }


    // Starts a trial.
    void action(Object caller, TestItem it, time tref, int count=-1)
    {
        // Save passed trial control parameters.
        item = it;
        sounds.size = 10;
        sounds[0] = item.sndfn1;
        sounds[1] = item.sndfn2;
        sounds[2] = item.sndfn3;
        sounds[3] = item.sndfn4;
        sounds[4] = item.sndfn5;
        sounds[5] = item.sndfn6;
        sounds[6] = item.sndfn7;
        sounds[7] = item.sndfn8;
        sounds[8] = item.sndfn9;
        sounds[9] = item.sndfn10;


        // Show this page (if necessary) and determine when the trial should
        // begin.
        tref = prepare_trial_start(tref);


        // Reset response data.
        response.clear();


        // Start attention getter. Attention getter finish event procedure
        // will start eye-tracker recording and visual stimulus.
        time attenoffset = layout.start_attention_getter(tref);

        // Start visual stimulus at attention getter offet + 
        // ATTEN_STIM_DELAY. Visual stimulus start event procedure will
        // start the audio stimulus and response period.
        time visstimonset = layout.start_stimulus(attenoffset + 
            ATTEN_STIM_DELAY);


        // Update status line on control window. Cleared in done() above.
        control.set_status(
            string(item.number) + "  " + 
            string(item.type));
            

        // Remember who to signal when the trial is over.
        target = caller;
    }
}
